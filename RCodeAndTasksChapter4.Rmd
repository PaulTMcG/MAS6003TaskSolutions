---
title: "R Code Chapter 4"
author: "Witold Wolski"
date: "December 23, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# 4.4.1 Model building for the beetle data

```{r}
getwd()

load("data/MAS367-GLMs.RData", envir = e <- new.env())
grep("beetle",names(e))
```

## Fitting minimal model

```{r}

beetle<-e$beetle
lapply(beetle,class)
head(beetle)
null.glm <- glm(propn.dead ~ 1, family=binomial(logit), weights=number, data=beetle)
null.glm
```

## Adding a log concentration term

```{r}
linear.glm <- glm(propn.dead~1+conc, binomial(logit), weights = number, data=beetle)
summary(linear.glm)
```

Example of computing $\chi^2$ values in R.

```{r}
sum(residuals(linear.glm, type = "pearson")^2)
```

## Numbers from point 3: Analysis of deviance in nested models

```{r}
null.glm$deviance
linear.glm$deviance
null.glm$deviance - linear.glm$deviance
qchisq(0.95,1)
```

##  Is fit acceptable ?

```{r}
qchisq(0.95,6)
```

## Plotting Pearson (?) residuals  against predicted values

```{r}
plot(linear.glm,which = 1)

```

## Fitting quadratic model


```{r}
quad.glm <- glm(propn.dead ~ 1 +conc+ I(conc^2), binomial(logit), weights= number, data= beetle)
quad.glm
```

## Change in deviance

```{r}
linear.glm$deviance - quad.glm$deviance 
qchisq(0.95,1)
qchisq(0.95,5)
plot(quad.glm,which = 1)

```


## 10 Wald t-test

```{r}
summary(quad.glm)

2*pnorm(-156.41/57.86)
```

# 4.4.2

```{r}
anova(linear.glm, quad.glm,test="Chi")
```

# 4.4.3

$AIC = -2l + 2p$

$\frac{l_min - l_mod}{l_min}$
```{r}
quad.glm$aic
l_mod<-length(quad.glm$coefficients) - 0.5*quad.glm$aic
l_min<-length(null.glm$coefficients) - 0.5*null.glm$aic
(l_min-l_mod)/l_min
```

# 4.4.4 Calculating residuals for the beetle quadratic model

```{r}
residuals(quad.glm,type = "pearson")

y=beetle$propn.dead
fitted = quad.glm$fitted
n = beetle$number
```

Lets define function:

```{r}
pearson_resid <- function(y, fitted, n){
  (y-fitted)/sqrt(fitted * (1-fitted)/n)
}
```
and run it:

```{r}
pearson_resid(y, fitted, n)
```

Other residuals are available:

Def function to compute $d_i$ deviance residuals:

```{r}
d_i_deviance <- function(y, fitted, n){
  sign(y- fitted)*sqrt(-2*n*(y*log(fitted/y)+(1-y)*log((1-fitted)/(1-y+0.0000001))))
}

d_i_deviance(y, fitted, n)
```

compare with r computed values

```{r}
residuals(quad.glm,type="deviance")
```

# Task 12

```{r}
residuals(linear.glm, "pearson")[1]
residuals(linear.glm, "deviance")[1]

linear.glm$fitted.values[1]
pearson_resid(linear.glm$y, linear.glm$fitted.values, linear.glm$prior.weights)
d_i_deviance(linear.glm$y, linear.glm$fitted.values, linear.glm$prior.weights)

```

# 4.4.5 Example 2 of model building : plant anthers


```{r}
anthers <- e$anthers
```

# Plot data 

```{r}
head(anthers)

anthers$p <- anthers$obtained/anthers$prepared

library(ggplot2)

ggplot(anthers, aes(force,p), colour= group) + geom_point()

```

## 2 consider logit link

```{r}
logit_link <- function(s,n){
  y <- (s + 1/2)/(n+1)
  log(y/(1-y))
}

```

```{r}
plot(log(anthers$force),logit_link(anthers$obtained,anthers$prepared))
```

## Minimal Model

```{r}
glm.0 <-glm(p ~ 1, weights = prepared, data = anthers, binomial(logit))
summary(glm.0)

```

## Model 1 

$\eta = \alpha$. Dobson is refernced, to make the lecture notes more confusing model 1 in dobson is model 3 in notes.

```{r}
anthers$p <- anthers$obtained/anthers$prepared
anthers$logForce <- log(anthers$force)
glm.1 <-glm(p ~ group, weights = prepared, data = anthers, family = binomial(logit))
summary(glm.1)
summary.lm(glm.1)

```

## Model 2

```{r}
anthers$p <- anthers$obtained/anthers$prepared
anthers$logForce <- log(anthers$force)
glm.2 <-glm(p ~ group + logForce, weights = prepared, data = anthers, family = binomial(logit))
summary(glm.2)
summary.lm(glm.2)
```

## Model 3

```{r}
lapply(anthers, class)
glm.3 <-glm(p ~ group * logForce , weights = prepared, data = anthers, family = binomial(logit))
summary(glm.3)

```

## Task 13

```{r}
glm.1 <-glm(p ~ group, weights = prepared, data = anthers, family = binomial(logit))
glm.1
glm.2 <-glm(p ~ group + force, weights = prepared, data = anthers, family = binomial(logit))
glm.2
```

The conlusions od not change at all. The residual deviances are for both models are rather similar.


# 4.5.1 (Task 14)

```{r}
grain <- e$grain



probit_link<- function(s,n){
  y<-(s+0.5)/(n+1) 
  (qnorm(y))
}

par(mfrow=c(1,2))
plot(grain$x, grain$s/ grain$n)
plot(grain$x, probit_link(grain$s, grain$n))
```

```{r}
head(grain)
grain$p_star <- (grain$s + 0.5)/ (grain$n+1)
grain$p <- (grain$s)/ (grain$n)
```


## 2 Null deviance

```{r}
glm(p ~ 1 , weights = grain$n, data= grain, family=binomial(link= 'probit'))
  
```

Can reproduce results from script only with p_start. But so far we only fitted models with $p = s/n$. Using `p_star` also produces a warning

```{r}
#glm(p_star ~ 1 + x , weights = grain$n, data= grain, family=binomial(link= 'probit'))
glin <- glm(p ~ 1 + x , weights = grain$n, data= grain, family=binomial(link= 'probit'))
names(glin)
glin$deviance
glin$null.deviance
glin$null.deviance-glin$deviance

```

The change in deviance (94 on 1 df) is clearly very high showing an
improvement of the model with a linear term over the null model (overwhelming evidence
to reject $H 0 : \beta_1 = 0$)

But the actual deviance for the model is high `r glin$deviance` providing evidence against this Binomial model 

$\chi^2_{8,0.9995}$ :

```{r}
qchisq(0.9995,8 )

```

## 5

Binomial model estimating $\phi$ as $D(y,\hat{\mu})/(n-p)$.
 
```{r}
glin$deviance / (glin$df.residual)

glq <- glm(p ~ 1 + x , weights = grain$n, data= grain, family=quasi)
glq$deviance

```

## 6

Standard errors for parameter estimates are then multiplied by:
 
```{r}
sqrt(glin$deviance / glin$df.residual)
```

## 7

Improvement over the null model on 1 df.

```{r}
(glin$null.deviance-glin$deviance)/ (glin$deviance / glin$df.residual)

```

The scaled deviance for this model:

```{r}
glin$deviance/(glin$deviance / glin$df.residual)
qchisq(0.95,7)
```

```{r}
sglin <- summary(glin)
```

with $e.s.e(\hat{\beta_1})=$ 

```{r}
sglin$coefficients[2,"Std. Error"]
sglin$coefficients[2,"Std. Error"] * sqrt(glin$deviance / glin$df.residual)
ese_b=sglin$coefficients[2,"Std. Error"] * sqrt(glin$deviance / glin$df.residual)

```

So the wald test statistics 

```{r}
coefficients(glin)[2]
coefficients(glin)[2] / ese_b
t = coefficients(glin)[2] / ese_b
```

The slope is highly significant.

```{r}
1-pt(t, df=7)
```

## using quasi (same as subsection 5)

```{r}
glq <- glm(p_star ~ 1 + x , weights = grain$n, data= grain, family=quasi())
glq$deviance
```

Somehow the numbers obtained are not equal to those in the lecture notes (3.62):
Also trying to run the glm with ```quasi(link = "probit", variance = "constant")```
does fail.




